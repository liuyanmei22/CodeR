{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFj/p563NXzI3GcSp3MTCy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuyanmei22/CodeR/blob/main/autogen_function_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE1cBZYkkc-f",
        "outputId": "333ace48-c96b-4251-90f8-54d3cd5d8d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \"pyautogen>=0.2.3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "chGTOUbAklNX",
        "outputId": "48b9e549-cc6e-4e83-967d-e2b74c802ba6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen>=0.2.3\n",
            "  Downloading pyautogen-0.2.31-py3-none-any.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.9/304.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache (from pyautogen>=0.2.3)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker (from pyautogen>=0.2.3)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flaml (from pyautogen>=0.2.3)\n",
            "  Downloading FLAML-2.1.2-py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen>=0.2.3) (1.25.2)\n",
            "Collecting openai>=1.3 (from pyautogen>=0.2.3)\n",
            "  Downloading openai-1.35.10-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen>=0.2.3) (24.1)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen>=0.2.3) (2.8.0)\n",
            "Collecting python-dotenv (from pyautogen>=0.2.3)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen>=0.2.3) (2.4.0)\n",
            "Collecting tiktoken (from pyautogen>=0.2.3)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen>=0.2.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen>=0.2.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen>=0.2.3)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen>=0.2.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen>=0.2.3) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen>=0.2.3) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen>=0.2.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen>=0.2.3) (2.20.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen>=0.2.3) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen>=0.2.3) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen>=0.2.3) (2024.5.15)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen>=0.2.3) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen>=0.2.3) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen>=0.2.3) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen>=0.2.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen>=0.2.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen>=0.2.3) (3.3.2)\n",
            "Installing collected packages: python-dotenv, h11, flaml, diskcache, tiktoken, httpcore, docker, httpx, openai, pyautogen\n",
            "Successfully installed diskcache-5.6.3 docker-7.1.0 flaml-2.1.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.10 pyautogen-0.2.31 python-dotenv-1.0.1 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import Annotated\n",
        "from autogen.coding import LocalCommandLineCodeExecutor\n",
        "\n",
        "\n",
        "import autogen\n",
        "from autogen.cache import Cache"
      ],
      "metadata": {
        "id": "AWzQZKe4lDdy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_list = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        "    filter_dict={\"model\": [\"glm-4\"]},  # comment out to get all\n",
        ")"
      ],
      "metadata": {
        "id": "x2JW2tzWlWZs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\n",
        "    \"config_list\": config_list,\n",
        "    \"timeout\": 120,\n",
        "}\n",
        "\n",
        "executor = LocalCommandLineCodeExecutor(\n",
        "    timeout=10,  # Timeout for each code execution in seconds.\n",
        "    work_dir=\".\",  # Use the temporary directory to store the code files.\n",
        ")\n",
        "\n",
        "chatbot = autogen.AssistantAgent(\n",
        "    name=\"chatbot\",\n",
        "    system_message=\"For currency exchange tasks, only use the functions you have been provided with. Reply TERMINATE when the task is done.\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "\n",
        "# create a UserProxyAgent instance named \"user_proxy\"\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"executor\": executor},  # Use the local command line code executor.\n",
        "\n",
        "    default_auto_reply=\"TERMINATE\",\n",
        "    max_consecutive_auto_reply=10,\n",
        ")"
      ],
      "metadata": {
        "id": "sYycT_wklhIb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CurrencySymbol = Literal[\"USD\", \"EUR\"]\n",
        "\n",
        "@user_proxy.register_for_execution()\n",
        "@chatbot.register_for_llm(description=\"calculate exchange_rate.\")\n",
        "def exchange_rate(base_currency: CurrencySymbol, quote_currency: CurrencySymbol) -> float:\n",
        "    if base_currency == quote_currency:\n",
        "        return 1.0\n",
        "    elif base_currency == \"USD\" and quote_currency == \"EUR\":\n",
        "        return 1 / 1.1\n",
        "    elif base_currency == \"EUR\" and quote_currency == \"USD\":\n",
        "        return 1.1\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown currencies {base_currency}, {quote_currency}\")\n",
        "\n",
        "\n",
        "@user_proxy.register_for_execution()\n",
        "@chatbot.register_for_llm(description=\"Currency exchange calculator.\")\n",
        "def currency_calculator(\n",
        "    base_amount: Annotated[float, \"Amount of currency in base_currency\"],\n",
        "    base_currency: Annotated[CurrencySymbol, \"Base currency\"] = \"USD\",\n",
        "    quote_currency: Annotated[CurrencySymbol, \"Quote currency\"] = \"EUR\",\n",
        ") -> str:\n",
        "    quote_amount = exchange_rate(base_currency, quote_currency) * base_amount\n",
        "    return f\"{quote_amount} {quote_currency}\""
      ],
      "metadata": {
        "id": "G4ttedFDlwSO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.llm_config[\"tools\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BObinzezl0Sa",
        "outputId": "6844f8bc-e0a5-440f-93d3-34811b65eca6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'function': {'description': 'calculate exchange_rate.',\n",
              "   'name': 'exchange_rate',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'base_currency': {'enum': ['USD', 'EUR'],\n",
              "      'type': 'string',\n",
              "      'description': 'base_currency'},\n",
              "     'quote_currency': {'enum': ['USD', 'EUR'],\n",
              "      'type': 'string',\n",
              "      'description': 'quote_currency'}},\n",
              "    'required': ['base_currency', 'quote_currency']}}},\n",
              " {'type': 'function',\n",
              "  'function': {'description': 'Currency exchange calculator.',\n",
              "   'name': 'currency_calculator',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'base_amount': {'type': 'number',\n",
              "      'description': 'Amount of currency in base_currency'},\n",
              "     'base_currency': {'enum': ['USD', 'EUR'],\n",
              "      'type': 'string',\n",
              "      'default': 'USD',\n",
              "      'description': 'Base currency'},\n",
              "     'quote_currency': {'enum': ['USD', 'EUR'],\n",
              "      'type': 'string',\n",
              "      'default': 'EUR',\n",
              "      'description': 'Quote currency'}},\n",
              "    'required': ['base_amount']}}}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = user_proxy.initiate_chat(\n",
        "    chatbot,\n",
        "    message=\"How much is 123.45 USD in EUR?\",\n",
        "    summary_method=\"reflection_with_llm\",\n",
        "    cache=cache\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcQasNiLmHsK",
        "outputId": "06192bba-7d83-4f38-9d7e-4fb11c0388ad"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to chatbot):\n",
            "\n",
            "How much is 123.45 USD in EUR?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 07-03 08:28:45] {315} WARNING - Model glm-4 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model glm-4 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chatbot (to user_proxy):\n",
            "\n",
            "\n",
            "***** Suggested tool call (call_8804456457550774147): currency_calculator *****\n",
            "Arguments: \n",
            "{\"base_amount\":123.45,\"base_currency\":\"USD\",\"quote_currency\":\"EUR\"}\n",
            "*******************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION currency_calculator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:autogen.runtime_logging:[runtime logging] log_function_use: autogen logger is None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to chatbot):\n",
            "\n",
            "user_proxy (to chatbot):\n",
            "\n",
            "***** Response from calling tool (call_8804456457550774147) *****\n",
            "112.22727272727272 EUR\n",
            "*****************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 07-03 08:28:59] {315} WARNING - Model glm-4 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model glm-4 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chatbot (to user_proxy):\n",
            "\n",
            "The exchange rate between USD and EUR is 1 USD = 0.9099999999999999 EUR. Using this rate, 123.45 USD is equivalent to 112.22727272727272 EUR.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "user_proxy (to chatbot):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 07-03 08:29:04] {315} WARNING - Model glm-4 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model glm-4 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        }
      ]
    }
  ]
}